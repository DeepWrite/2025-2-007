---
title: 007-13 김강현 (과제-03)
layout: home
nav_order: 13
parent: 과제-03 쟁점과 딜레마 분석
permalink: /asmt-03/007-13
---

# 과제-03 쟁점과 딜레마 분석 007-13 김강현 

## 1. 관심 주제 및 일반적 배경

**자율주행자동차 기술**은 미래 교통의 혁신으로 각광받지만, 실제 운행 과정에서 피할 수 없는 도덕적 선택(윤리적 딜레마)에 직면한다. 차량이 위급 상황에서 사고를 피할 수 없을 때, 어떤 생명을 우선 보호해야 할지 판단해야 하며, 이 결정의 책임과 기준에 대해 사회적 논의가 요구된다. 자율주행차의 알고리즘 구조는 단순한 기술적 효율성 문제가 아니라, **생명 가치**, **책임 분배**, **공공선** 등 민주적 가치와 밀접히 연동된다. 본 과제에서는 자율주행차 알고리즘에서 어떤 규범적 책임성과 공적 통제가 필요한지를 분석하고자 한다.

---

## 2. 논쟁 중인 학술적 쟁점 (Core Issue)

### 주요 쟁점:  

> *자율주행차 알고리즘의 윤리적 의사결정은 단순히 객관적 위험 최소화를 목적으로 해야하는 것인가, 아니면 사회가 합의한 민주적, 생명의 평등 원칙에 의해 통제되어야 하는가?*

### 상반된 입장:
- **Jean-François Bonnefon et al. (2016)**는 **사고 상황에서 다수를 살리는 것이 사회적으로 선호**된다는 점을 확인했으나, 이것이 정책에 직접 적용될 수 있는지는 논쟁이 있다.
- 반면, **Gurney, Hevelke & Nida-Rümelin (2015)**, **Sven Nyholm (2018)**은 인간 생명의 가치에 서열을 둘 수 없으며, 사고 알고리즘의 도덕적 정당성은 **사회적 합의, 투명한 절차가 필요**하다고 주장한다.

---

## 3. 촉발되는 딜레마 또는 난제 (Dilemma / Hard Question)

- **딜레마**: 
  - 자율주행차는 위급 상황에서 **한 명을 살리기 위해 여러 명을 희생** 또는 **탑승자 우선/보행자 우선** 등 특정 규칙을 따르도록 설계될 수 있다.  
  - 그러나 이 기준을 단순히 객관적 위험 최소화를 목적으로 소프트웨어 개발자나 기업 내부가 독점적으로 결정할 경우, **사회 전체의 생명권과 민주주의 원리가 침해**된다. 반대로, 강력한 공적 개입은 **기술 혁신을 위축시키거나 개인 선택권을 제한**할 수 있다.
- **과제 질문**: 그렇다면 자율주행차 알고리즘의 설계와 작동에 대해 **어떤 민주적 통제, 규범적 책임원칙이 요구되는가?** 이 책임은 누구에게, 어떤 방식으로 귀속되어야 하는가?

---

## 4. 관련 학자 및 입장 정리

| 학자명             | 대표 저작/논문                                   | 입장 요약 |
|--------------------|---------------------------------------------------|-----------|
| Jean-François Bonnefon 외   | “The Social Dilemma of Autonomous Vehicles” (2016)                          | 다수의 생명을 구하는 utilitarian 기준이 사회적 선호이다. |
| Gurney, Hevelke & Nida-Rümelin    | “Autonomous Vehicles and Public Policy: The Next Step” (2015)                                | 인명에 서열 부여는 위험하고, 공적 토론과 규칙 설정이 필요하다. |
| Sven Nyholm     | “The Ethics of Accident-Algorithms for Self-Driving Cars” (2018) | 사고 알고리즘의 도덕적 정당성은 사회적 합의, 투명한 절차가 필요하다. |

---

## 5. 나의 문제의식 (초기 주장의 방향)

나는 자율주행자동차 알고리즘의 결정구조를 단순히 기술적 최적화 문제로 보는 것은 위험하다고 생각한다. 자율주행차 알고리즘을 단순히 객관적 위험 최소화를 목적으로 기업 내부에서 독점적으로 결정할 경우, 생명 경시, 약자 차별 등 사회적 불평등을 정당화할 위험이 있다. 이의 방지와 투명성, 공정성을 위해서는 **의사결정 논리의 공개와 사회적 공론화**, **다양한 사회계층이 참여하는 민주적 숙의와 규범 확립**, **기업과 개발자에게만 한정되지 않는 다중적 책임구조의 확보** 등이 필요하다. 논증문에서는 이러한 주장을 **Gurney, Hevelke & Nida-Rümelin의 공적 토론과 규칙 설정이 필요성**과 **Sven Nyholm의 사회적 합의, 투명한 절차의 필요성**을 중심으로 전개할 것이다.
---

## 6. 참고문헌

- Bonnefon, J.-F., Shariff, A., & Rahwan, I. (2016). The Social Dilemma of Autonomous Vehicles. Science, 352(6293), 1573–1576.
- Hevelke, A., & Nida-Rümelin, J. (2015). Responsibility for Crashes of Autonomous Vehicles: An Ethical Analysis. Science and Engineering Ethics.
- Nyholm, S. (2018). The Ethics of Accident-Algorithms for Self-Driving Cars. Elsevier.
